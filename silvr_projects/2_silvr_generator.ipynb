{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d42d3c",
   "metadata": {},
   "source": [
    "# SILVR Generator code. This code runs the samples. \n",
    "\n",
    "Initial commit - may not run as current. \n",
    "\n",
    "This notebook can be run in browser, however it should be run as nohup when a large number of samples are desired. In current 4 GPU setup, 1000 samples takes around 3 hours. \n",
    "\n",
    "\n",
    "Notes: Multiprocessing has been coded here to allow parallel sampling on multiple GPUs. In order to get this to work I had to do a slightly hacky method. This code was developed to run on 4 GPUs. The multiprocessing section creates 4 processes: one process running on each GPU. The process keeps sampling SILVR until the experiment directory is filled with the required number of samples. At this point, the sampling stops. This means if you run an experiment for 1000 samples, then attempt to run the same experiment directory again, no further samples will be generated unless you delete the current samples within the experiment directory. \n",
    "\n",
    "To enable parallel GPU processing, the hacky bit comes from `cuda:{gpu}`. They way I have implemented this is not particularly maintainable and should be clarified in the future, however essentially I have a list of my GPUs `[cuda:0, cuda:1, cuda:2, cuda:3]` and then for each GPU I start a new SILVR process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f615bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "_ = (sys.path.append(\"/usr/local/lib/python3.8/site-packages\"))\n",
    "_ = (sys.path.append(\"e3_diffusion_for_molecules\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92381913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_sample\n",
    "\n",
    "# Rdkit import should be first, do not move it\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "except ModuleNotFoundError:\n",
    "    pass\n",
    "\n",
    "import utils\n",
    "import argparse\n",
    "from configs.datasets_config import qm9_with_h, qm9_without_h\n",
    "from qm9 import dataset\n",
    "from qm9.models import get_model\n",
    "\n",
    "from equivariant_diffusion.utils import assert_correctly_masked\n",
    "import torch\n",
    "import pickle\n",
    "import qm9.visualizer as vis\n",
    "from qm9.analyze import check_stability\n",
    "from os.path import join\n",
    "from qm9.sampling import sample_chain, sample\n",
    "from configs.datasets_config import get_dataset_info\n",
    "\n",
    "\n",
    "################\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "import numpy as np\n",
    "from egnn.models import EGNN_dynamics_QM9\n",
    "\n",
    "from equivariant_diffusion.en_diffusion import EnVariationalDiffusion\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from equivariant_diffusion.utils import assert_mean_zero_with_mask, remove_mean_with_mask,\\\n",
    "    assert_correctly_masked\n",
    "from qm9.analyze import check_stability\n",
    "\n",
    "\n",
    "####################\n",
    "from qm9.analyze import check_stability\n",
    "from argparse import Namespace\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "####################\n",
    "from multiprocessing import Process\n",
    "import time\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32100b",
   "metadata": {},
   "source": [
    "# Read sxyz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87bdc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sxyz(file):\n",
    "    \"\"\"\n",
    "    Read reference.sxyz file and parse into correct format for silvr\n",
    "    \n",
    "    ---explanation of parsing---\n",
    "    Line[0] contains total atoms in the reference. This is the same as for an xyz file\n",
    "    line[1] contains experimental set up params\n",
    "        dummy: Number of additional atoms to add that are not contained within the reference\n",
    "        sample: how many molecules should be generated. Molecules are generated serially, so samples\n",
    "                defines iterations in a for loop\n",
    "                nb: future work should look at parallelisation\n",
    "        comment: This does not affect model running\n",
    "        \n",
    "    lines[2:] contain all xyz and silvr rate information: element X Y Z rate\n",
    "        element is converted to float of atomic number\n",
    "        X Y Z are retained\n",
    "        rate is appended to the SILVR vector \n",
    "        \n",
    "    returns\n",
    "        ref_coords (2D array): atomic number and reference coordinates\n",
    "        total_atoms (int): total number of atoms to be in each sampled molecule (ie 40 = 40 atoms in generated molecule)\n",
    "        n_samples: Number of samples to take\n",
    "        silvr_vector (1D array): containing rates to be used in SILVR protocol\n",
    "            where values are 0 this means no weighting applied to atom\n",
    "            where values are 1 this mean total weighting for atom, essentially total replacement of generated \n",
    "                atoms with reference atom\n",
    "            generally rate=0.01 works well\n",
    "    \"\"\"\n",
    "    n_ref = 0\n",
    "    n_dummy = 0\n",
    "    n_samples = 0\n",
    "    ref_coords = []\n",
    "    silvr_vector = []\n",
    "    \n",
    "    with open(file, \"r\") as readfile:\n",
    "        txt = readfile.read().split(\"\\n\")\n",
    "        n_ref = int(txt[0])\n",
    "        n_dummy = int(txt[1].split()[0].split(\":\")[1])\n",
    "        n_samples = int(txt[1].split()[1].split(\":\")[1])\n",
    "        \n",
    "        #atom mapping \n",
    "        atomic_number_map = {\"H\":1,\"B\":5,\"C\":6,\"N\":7,\"O\":8,\"F\":9,\"P\":15,\"S\":16,\"Cl\":17,\"br\":35}\n",
    "        \n",
    "        for line in txt[2:]:\n",
    "            line = line.split()\n",
    "            xyz = [float(x) for x in line[1:4]]\n",
    "            atomic_number = atomic_number_map[line[0]]            \n",
    "            ref_coords.append([atomic_number]+xyz)\n",
    "            silvr_vector.append(float(line[4]))\n",
    "            \n",
    "    total_atoms = n_ref + n_dummy\n",
    "            \n",
    "    return ref_coords, total_atoms, n_samples, silvr_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096a948",
   "metadata": {},
   "source": [
    "# SILVR class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cab22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------SILVR-------------------\n",
    "class silvr():\n",
    "    def __init__(self, \n",
    "                args=None,\n",
    "                device=None,\n",
    "                flow=None,\n",
    "                dataset_info=None,\n",
    "                total_atoms=None,\n",
    "                silvr_rate=0.01,\n",
    "                ref_coords=None,\n",
    "                n_samples=1,\n",
    "                out_dir_path=\"outputs/\",\n",
    "                gpu=None):\n",
    "    \n",
    "        if total_atoms < len(ref_coords):\n",
    "            #Total atoms must be at least the number as in the reference\n",
    "            total_atoms = len(ref_coords)\n",
    "\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        self.flow = flow\n",
    "        self.dataset_info = dataset_info\n",
    "        self.max_n_nodes = self.dataset_info['max_n_nodes']\n",
    "        self.total_atoms = total_atoms\n",
    "        self.node_mask, self.edge_mask = self.make_node_mask()\n",
    "        self.ref_coords = ref_coords\n",
    "        self.ref_node_mask = self.set_ref_node_mask()   \n",
    "        self.n_samples = n_samples\n",
    "        self.gpu = gpu\n",
    "        \n",
    "        #if path doesn't exist, make path\n",
    "        self.out_dir_path = out_dir_path\n",
    "        if not os.path.exists(self.out_dir_path):\n",
    "            os.makedirs(self.out_dir_path)\n",
    "            \n",
    "        #Convert silvr_rate list to tensor of correct shape\n",
    "        if isinstance(silvr_rate, list):\n",
    "            silvr_tensor = torch.zeros(self.max_n_nodes).to(device=self.device)\n",
    "            silvr_tensor[:len(silvr_rate)] = torch.Tensor(silvr_rate)\n",
    "            silvr_tensor = torch.unsqueeze(silvr_tensor, 0)\n",
    "            silvr_tensor = torch.unsqueeze(silvr_tensor, 2)\n",
    "        self.silvr_rate = silvr_tensor\n",
    "            \n",
    "\n",
    "    def make_node_mask(self, number=None):\n",
    "        if number:\n",
    "            nodesxsample = torch.tensor([atomic_numbers])\n",
    "        else:\n",
    "            nodesxsample = torch.tensor([self.total_atoms])\n",
    "            max_n_nodes = self.dataset_info['max_n_nodes']  # this is the maximum node_size in QM9\n",
    "\n",
    "            assert int(torch.max(nodesxsample)) <= max_n_nodes\n",
    "            batch_size = len(nodesxsample)\n",
    "\n",
    "            node_mask = torch.zeros(batch_size, max_n_nodes)\n",
    "            for i in range(batch_size):\n",
    "                node_mask[i, 0:nodesxsample[i]] = 1\n",
    "\n",
    "        # Compute edge_mask\n",
    "        edge_mask = node_mask.unsqueeze(1) * node_mask.unsqueeze(2)\n",
    "        diag_mask = ~torch.eye(edge_mask.size(1), dtype=torch.bool).unsqueeze(0)\n",
    "        edge_mask *= diag_mask\n",
    "        edge_mask = edge_mask.view(batch_size * max_n_nodes * max_n_nodes, 1).to(self.device)\n",
    "        node_mask = node_mask.unsqueeze(2).to(self.device)\n",
    "\n",
    "        self.edge_mask = edge_mask\n",
    "        self.node_mask = node_mask\n",
    "\n",
    "        return node_mask, edge_mask\n",
    "    \n",
    "    \n",
    "    def set_ref_node_mask(self, number=None):\n",
    "        if number:\n",
    "            nodesxsample2=torch.tensor([number])\n",
    "        elif self.ref_coords:\n",
    "            nodesxsample2=torch.tensor([len(self.ref_coords)])\n",
    "        else:\n",
    "            nodesxsample2=torch.tensor([self.total_atoms])\n",
    "\n",
    "        batch_size2 = len(nodesxsample2)\n",
    "        node_mask2 = torch.zeros(batch_size2, self.max_n_nodes)\n",
    "        for i in range(batch_size2):\n",
    "            node_mask2[i, 0:nodesxsample2[i]] = 1\n",
    "        self.ref_node_mask = node_mask2.unsqueeze(2).to(self.device)\n",
    "\n",
    "        return self.ref_node_mask\n",
    "    \n",
    "    \n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Samples diffusion model with SILVR\n",
    "        Returns one_hot encoding, charges, coordinates, and atom mask\n",
    "        These can be converted into an XYZ file\n",
    "        \"\"\"\n",
    "        context = None\n",
    "        x, h = self.flow.sample(self.n_samples, \n",
    "                                   self.max_n_nodes, \n",
    "                                   self.node_mask, \n",
    "                                   self.edge_mask, \n",
    "                                   context, \n",
    "                                   fix_noise=False, \n",
    "                                   silvr_rate=self.silvr_rate,\n",
    "                                   ref_coords=self.ref_coords,\n",
    "                                   ref_node_mask=self.ref_node_mask,\n",
    "                                    shift_centre=True,\n",
    "                                  dataset_info=self.dataset_info\n",
    "                            )\n",
    "\n",
    "        assert_correctly_masked(x, self.node_mask)\n",
    "        one_hot = h['categorical']\n",
    "        charges = h['integer']\n",
    "        assert_correctly_masked(one_hot.float(), self.node_mask)\n",
    "        if self.args.include_charges:\n",
    "            assert_correctly_masked(charges.float(), self.node_mask)\n",
    "\n",
    "        return one_hot, charges, x, self.node_mask\n",
    "\n",
    "\n",
    "\n",
    "    def sample_xyz(self):\n",
    "        \"\"\"\n",
    "        Samples the SILVR model\n",
    "        Outputs XYZ file with stability information\n",
    "        Returns id of file\n",
    "            Note files are saves as mol_{mol_id}_000.txt\n",
    "        \"\"\"\n",
    "        #run sampling\n",
    "        one_hot, charges, x, node_mask = self.sample()\n",
    "        now = datetime.datetime.now()\n",
    "        mol_id = now.strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "        \n",
    "        #Convert sample to xyz file\n",
    "        vis.save_xyz_file(\n",
    "          self.out_dir_path, one_hot, charges, x,\n",
    "          id_from=0, name=f'mol_{mol_id}{self.gpu}', dataset_info=self.dataset_info,\n",
    "          node_mask=node_mask)\n",
    "        \n",
    "        #Add stability information to xyz file\n",
    "        i = 0\n",
    "        num_atoms = int(node_mask[i:i+1].sum().item())\n",
    "        atom_type = one_hot[i:i+1, :num_atoms].argmax(2).squeeze(0).cpu().detach().numpy()\n",
    "        x_squeeze = x[i:i+1, :num_atoms].squeeze(0).cpu().detach().numpy()\n",
    "        mol_stable = check_stability(x_squeeze, atom_type, self.dataset_info)\n",
    "        stability_string = f\"stable:{mol_stable[0]} satoms:{mol_stable[1]} tatoms:{mol_stable[2]} sratio:{mol_stable[1]/mol_stable[2]}\\n\"\n",
    "\n",
    "        with open(f'{self.out_dir_path}mol_{mol_id}{self.gpu}_000.txt', \"r\") as readfile:\n",
    "            data = readfile.readlines()\n",
    "        readfile.close()\n",
    "        data[1] = stability_string\n",
    "        with open(f'{self.out_dir_path}mol_{mol_id}{self.gpu}_000.txt', \"w\") as writefile:\n",
    "            writefile.writelines(data)\n",
    "        writefile.close()\n",
    "\n",
    "        #return name of molecule file\n",
    "        return(mol_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7364a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of n_nodes: H[N] -3.718651056289673\n",
      "Entropy of n_nodes: H[N]Entropy of n_nodes: H[N] Entropy of n_nodes: H[N] -3.718651056289673 -3.718651056289673\n",
      "-3.718651056289673\n",
      "\n",
      "alphas2alphas2  [9.99990000e-01 9.99988000e-01 9.99982000e-01 ... 2.59676966e-05\n",
      " 1.39959211e-05 1.00039959e-05]\n",
      "[9.99990000e-01 9.99988000e-01 9.99982000e-01 ... 2.59676966e-05\n",
      " 1.39959211e-05 1.00039959e-05]gamma\n",
      " [-11.51291546 -11.33059532 -10.92513058 ...  10.55863126  11.17673063\n",
      "  11.51251595]gamma\n",
      " [-11.51291546 -11.33059532 -10.92513058 ...  10.55863126  11.17673063\n",
      "  11.51251595]\n",
      "alphas2 [9.99990000e-01 9.99988000e-01 9.99982000e-01 ... 2.59676966e-05\n",
      " 1.39959211e-05 1.00039959e-05]alphas2\n",
      " gamma [9.99990000e-01 9.99988000e-01 9.99982000e-01 ... 2.59676966e-05\n",
      " 1.39959211e-05 1.00039959e-05]\n",
      "[-11.51291546 -11.33059532 -10.92513058 ...  10.55863126  11.17673063\n",
      "  11.51251595]gamma\n",
      " [-11.51291546 -11.33059532 -10.92513058 ...  10.55863126  11.17673063\n",
      "  11.51251595]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n",
      "Process Process-9:\n",
      "Process Process-11:\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_2387774/2216345187.py\", line 52, in run_exp\n",
      "    silvr_model.sample_xyz()\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_2387774/2216345187.py\", line 52, in run_exp\n",
      "    silvr_model.sample_xyz()\n",
      "  File \"/tmp/ipykernel_2387774/2752196793.py\", line 129, in sample_xyz\n",
      "    one_hot, charges, x, node_mask = self.sample()\n",
      "  File \"/tmp/ipykernel_2387774/2216345187.py\", line 52, in run_exp\n",
      "    silvr_model.sample_xyz()\n",
      "  File \"/tmp/ipykernel_2387774/2752196793.py\", line 129, in sample_xyz\n",
      "    one_hot, charges, x, node_mask = self.sample()\n",
      "  File \"/tmp/ipykernel_2387774/2752196793.py\", line 97, in sample\n",
      "    x, h = self.flow.sample(self.n_samples,\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2387774/2752196793.py\", line 129, in sample_xyz\n",
      "    one_hot, charges, x, node_mask = self.sample()\n",
      "  File \"/tmp/ipykernel_2387774/2752196793.py\", line 97, in sample\n",
      "    x, h = self.flow.sample(self.n_samples,\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_2387774/2752196793.py\", line 97, in sample\n",
      "    x, h = self.flow.sample(self.n_samples,\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 967, in sample\n",
      "    z = self.sample_p_zs_given_zt(s_array, t_array, z, node_mask, edge_mask, context, fix_noise=fix_noise)\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 726, in sample_p_zs_given_zt\n",
      "    eps_t = self.phi(zt, t, node_mask, edge_mask, context)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 967, in sample\n",
      "    z = self.sample_p_zs_given_zt(s_array, t_array, z, node_mask, edge_mask, context, fix_noise=fix_noise)\n",
      "  File \"/tmp/ipykernel_2387774/2216345187.py\", line 52, in run_exp\n",
      "    silvr_model.sample_xyz()\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 967, in sample\n",
      "    z = self.sample_p_zs_given_zt(s_array, t_array, z, node_mask, edge_mask, context, fix_noise=fix_noise)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 726, in sample_p_zs_given_zt\n",
      "    eps_t = self.phi(zt, t, node_mask, edge_mask, context)\n",
      "  File \"/tmp/ipykernel_2387774/2752196793.py\", line 129, in sample_xyz\n",
      "    one_hot, charges, x, node_mask = self.sample()\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 313, in phi\n",
      "    net_out = self.dynamics._forward(t, x, node_mask, edge_mask, context)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 726, in sample_p_zs_given_zt\n",
      "    eps_t = self.phi(zt, t, node_mask, edge_mask, context)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 313, in phi\n",
      "    net_out = self.dynamics._forward(t, x, node_mask, edge_mask, context)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/egnn/models.py\", line 100, in _forward\n",
      "    if torch.any(torch.isnan(vel)):\n",
      "  File \"/tmp/ipykernel_2387774/2752196793.py\", line 97, in sample\n",
      "    x, h = self.flow.sample(self.n_samples,\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 313, in phi\n",
      "    net_out = self.dynamics._forward(t, x, node_mask, edge_mask, context)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/egnn/models.py\", line 100, in _forward\n",
      "    if torch.any(torch.isnan(vel)):\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/egnn/models.py\", line 100, in _forward\n",
      "    if torch.any(torch.isnan(vel)):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 967, in sample\n",
      "    z = self.sample_p_zs_given_zt(s_array, t_array, z, node_mask, edge_mask, context, fix_noise=fix_noise)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 726, in sample_p_zs_given_zt\n",
      "    eps_t = self.phi(zt, t, node_mask, edge_mask, context)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py\", line 313, in phi\n",
      "    net_out = self.dynamics._forward(t, x, node_mask, edge_mask, context)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/egnn/models.py\", line 79, in _forward\n",
      "    h_final, x_final = self.egnn(h, x, edges, node_mask=node_mask, edge_mask=edge_mask)\n",
      "  File \"/home/nichrun/miniconda3/envs/difflinker/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/nichrun/Documents/silvr_project/e3_diffusion_for_molecules/egnn/egnn_new.py\", line 186, in forward\n",
      "    distances, _ = coord2diff(x, edge_index)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m#Run all experiments\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp_directory \u001b[38;5;129;01min\u001b[39;00m exp_to_run:\n\u001b[0;32m--> 122\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(exp_directory)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m#Blocking process until completion\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m processes:\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#----Logging----\u001b[39;00m\n\u001b[1;32m     88\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWNOHANG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n",
      "File \u001b[0;32m~/miniconda3/envs/difflinker/lib/python3.10/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_exp(gpu, exp_directory):\n",
    "    #1 Model imports\n",
    "    #--------------Model path--------------------\n",
    "    model_path = \"e3_diffusion_for_molecules/outputs/edm_geom_drugs/\"\n",
    "\n",
    "    #------------------Get model arguments-------------------\n",
    "    assert model_path is not None\n",
    "    with open(join(model_path, 'args.pickle'), 'rb') as f:\n",
    "        args = pickle.load(f)\n",
    "\n",
    "    #------------Don't know what this is---------------------\n",
    "    # CAREFUL with this -->\n",
    "    if not hasattr(args, 'normalization_factor'):\n",
    "        args.normalization_factor = 1\n",
    "    if not hasattr(args, 'aggregation_method'):\n",
    "        args.aggregation_method = 'sum'\n",
    "\n",
    "    #-------------Setting Cuda-----------------------\n",
    "    #Limited CUDA?\n",
    "    args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(f\"cuda:{gpu}\" if args.cuda else \"cpu\")\n",
    "    args.device = device\n",
    "    dtype = torch.float32\n",
    "    utils.create_folders(args)\n",
    "\n",
    "    #-------------Loading arguments needed for model----------------------\n",
    "    from configs.datasets_config import geom_with_h, geom_no_h\n",
    "    dataset_info = get_dataset_info(args.dataset, args.remove_h)\n",
    "\n",
    "    #---------Getting Model-------------\n",
    "    flow, nodes_dist, prop_dist = get_model(args, device, dataset_info, None)\n",
    "    flow.to(device)\n",
    "\n",
    "    #-----------getting additional params?--------------\n",
    "    fn = 'generative_model_ema.npy' if args.ema_decay > 0 else 'generative_model.npy'\n",
    "    flow_state_dict = torch.load(join(model_path, fn),map_location=device)\n",
    "    flow.load_state_dict(flow_state_dict)\n",
    "    \n",
    "    \n",
    "    #exp direcotry and reference coords etc was here\n",
    "    ref_coords, total_atoms, n_samples, silvr_vector = read_sxyz(f\"{exp_directory}reference.sxyz\")\n",
    "    \n",
    "    \n",
    "    #2 Create SILVR object\n",
    "    silvr_model = silvr(args=args,device=device,flow=flow,\n",
    "                   dataset_info=dataset_info,total_atoms=total_atoms,\n",
    "                   silvr_rate=silvr_vector,ref_coords=ref_coords,\n",
    "                   n_samples=1, out_dir_path=exp_directory, gpu=gpu)\n",
    "    \n",
    "    \n",
    "    while len(os.listdir(exp_directory)) < n_samples+2:\n",
    "        silvr_model.sample_xyz()\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "def main(exp_directory):\n",
    "    n_gpu = 4\n",
    "    \n",
    "    processes = []\n",
    "    for gpu in range(n_gpu):\n",
    "        p = Process(target=run_exp, args=(gpu,exp_directory))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    \n",
    "    #----Logging----\n",
    "    t1 = time.time()\n",
    "    now = datetime.datetime.now()\n",
    "    time_now = now.strftime(\"%Y %m %d %H:%M:%S\")\n",
    "    with open(f\"{exp_directory}reference.sxyz\", \"r\") as readfile:\n",
    "        ref_file = readfile.read().split(\"\\n\")\n",
    "        total_atoms = ref_file[0]\n",
    "        comment_line = ref_file[1]\n",
    "    with open(\"experiments/log.txt\", \"a\") as file:\n",
    "        file.write(f\"Running: {exp_directory}\\n\")\n",
    "        file.write(f\"Total atoms: {total_atoms}\\n\")\n",
    "        file.write(f\"{comment_line}\\n\")\n",
    "        file.write(f\"gpus: {n_gpu}\\n\")\n",
    "        file.write(f\"Start: {time_now}\\n\")\n",
    "\n",
    "    \n",
    "    #Blocking process until completion\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        \n",
    "    \n",
    "    #----Logging----\n",
    "    t2 = time.time()\n",
    "    now = datetime.datetime.now()\n",
    "    time_now = now.strftime(\"%Y %m %d %H:%M:%S\")\n",
    "    with open(\"experiments/log.txt\", \"a\") as file:\n",
    "        file.write(f\"End: {time_now}\\n\")\n",
    "        file.write(f\"Total time (min): {round((t2-t1)/60, 3)}\\n\")\n",
    "        file.write(\"------------------\\n\")\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    ###################### EDIT HERE #####################################\n",
    "    #state which directories contain the experiment to be run\n",
    "    #working_dir = \"experiments/\"\n",
    "    #exp_nums = [1,2,3]\n",
    "    #exp_to_run = [f\"{working_dir}rec_{x}/\" for x in exp_nums]\n",
    "    \n",
    "    exp_to_run = ['experiments/exp_37/',]\n",
    "                 #'experiments/exp_30/',\n",
    "                 #'experiments/exp_31/',\n",
    "                 #'experiments/exp_32/',\n",
    "                 #'experiments/exp_33/',\n",
    "                 #'experiments/exp_34/',\n",
    "                 #'experiments/exp_35/']\n",
    "    \n",
    "    ######################################################################\n",
    "\n",
    "    #Check that directory contains an appropriate reference file\n",
    "    for d in exp_to_run:\n",
    "        path_to_ref = f\"{d}reference.sxyz\"\n",
    "        if not os.path.isfile(path_to_ref):\n",
    "            raise Exception(\"Error in reference\")\n",
    "    \n",
    "    #Run all experiments\n",
    "    for exp_directory in exp_to_run:\n",
    "        main(exp_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1ee9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d51ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
